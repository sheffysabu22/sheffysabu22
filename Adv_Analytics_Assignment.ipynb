# Import Libraries
import pandas as pd
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/Youth_Tobacco_Survey__YTS__Data.csv')

# Handle missing values
df_cleaned = df.dropna(subset=['Data_Value', 'Response'])  
df_cleaned = df_cleaned.fillna(0)

# Convert categorical variables
df_cleaned = pd.get_dummies(df_cleaned, columns=['LocationAbbr', 'TopicType', 'Gender', 'Race', 'Age', 'Education'])

# Scale numerical features
scaler = StandardScaler()
numerical_features = df_cleaned.select_dtypes(include=['float64', 'int64']).columns
df_cleaned[numerical_features] = scaler.fit_transform(df_cleaned[numerical_features])

# Select features for clustering
features_for_clustering = df_cleaned[['Data_Value', 'Low_Confidence_Limit', 'High_Confidence_Limit', 'Sample_Size']]

# DBSCAN Clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
df_cleaned['Cluster_Labels'] = dbscan.fit_predict(features_for_clustering)

# Silhouette Score
silhouette_avg = silhouette_score(features_for_clustering, df_cleaned['Cluster_Labels'])
print(f"Silhouette Score: {silhouette_avg}")

# Visualize Clusters using PCA
pca = PCA(n_components= 2)
pca_result = pca.fit_transform(features_for_clustering)

# Create a DataFrame for visualization
df_pca = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])
df_pca['Cluster_Labels'] = df_cleaned['Cluster_Labels']

# Scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster_Labels', data=df_pca, palette='viridis', s=50)
plt.title('DBSCAN Clustering Results with PCA')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(loc='best')
plt.show()

print(features_for_clustering.shape)

print(num_components)

# Change the number of components to be less than or equal to the minimum of the number of samples and features
num_components = min(features_for_clustering.shape[0], features_for_clustering.shape[1]) - 1

# Perform PCA with the corrected number of components
pca = PCA(n_components=num_components)
pca_result = pca.fit_transform(features_for_clustering)

# Create a DataFrame for visualization
pca_columns = [f'PC{i+1}' for i in range(num_components)]
df_pca = pd.DataFrame(data=pca_result, columns=pca_columns)
df_pca['Cluster_Labels'] = df_cleaned['Cluster_Labels']

# Scatter plot of the first two principal components
plt.figure(figsize=(10, 6))
sns.scatterplot(x='PC1', y='PC3', hue='Cluster_Labels', data=df_pca, palette='viridis', s=50)
plt.title('PCA of Clustering Results')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 3')
plt.legend(loc='best')
plt.show()

# Explained Variance Ratio
explained_variance_ratio = pca.explained_variance_ratio_
print(f"Explained Variance Ratio: {explained_variance_ratio}")

# Cumulative Explained Variance
cumulative_explained_variance = explained_variance_ratio.cumsum()
print(f"Cumulative Explained Variance: {cumulative_explained_variance}")

#Scatter plot of another pair of principal components
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Low_Confidence_Limit', y='High_Confidence_Limit', hue='Cluster_Labels', data=df_cleaned, palette='viridis', s=50)
plt.title('DBSCAN Clustering Results')
plt.xlabel('Low_Confidence_Limit')
plt.ylabel('High_Confidence_Limit')
plt.legend(loc='best')
plt.show()

# Box Plot for Clustering Features
plt.figure(figsize=(10, 5))
sns.boxplot(x='Cluster_Labels', y='Data_Value', data=df_cleaned, palette='viridis')
plt.title('Box Plot of Data_Value by Cluster')
plt.show()

# Histogram of Cluster Sizes
plt.figure(figsize=(6, 3))
sns.histplot(df_cleaned['Cluster_Labels'], bins=len(df_cleaned['Cluster_Labels'].unique()), kde=False, color='skyblue')
plt.title('Histogram of Cluster Sizes')
plt.xlabel('Cluster Labels')
plt.ylabel('Number of Instances')
plt.show()

# 3D Scatter Plot for Three Features
fig = plt.figure(figsize=(10, 6))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(df_cleaned['Data_Value'], df_cleaned['Low_Confidence_Limit'], df_cleaned['High_Confidence_Limit'], c=df_cleaned['Cluster_Labels'], cmap='viridis', s=50)
ax.set_xlabel('Data_Value')
ax.set_ylabel('Low_Confidence_Limit')
ax.set_zlabel('High_Confidence_Limit')
ax.set_title('3D Scatter Plot of Clustering Results')
fig.colorbar(scatter, ax=ax, label='Cluster Labels')
plt.show()

# Calculate cluster centers
cluster_centers = df_cleaned.groupby('Cluster_Labels').mean()

# Heatmap of Cluster Centers
plt.figure(figsize=(10, 6))
sns.heatmap(cluster_centers, cmap='viridis', annot=True, fmt=".2f")
plt.title('Heatmap of Cluster Centers')
plt.show()

# Count Plot of a Categorical Feature by Cluster
plt.figure(figsize=(12, 6))
sns.countplot(x='Gender_Female', hue='Cluster_Labels', data=df_cleaned, palette='viridis')
plt.title('Count Plot of Gender by Cluster')
plt.show()
